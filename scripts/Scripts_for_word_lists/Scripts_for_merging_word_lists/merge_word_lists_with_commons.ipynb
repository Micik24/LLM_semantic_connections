{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fc80d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INPUT ===\n",
      "file1: NGSL_lists\\NGSL-GR_rank.csv (encoding: utf-8-sig)\n",
      "file2: 4_NGSL_lists_combined.csv (encoding: utf-8-sig)\n",
      "\n",
      "=== UNIQUE VOCAB (SETS) ===\n",
      "Unique vocab in file1: 5051\n",
      "Unique vocab in file2: 4832\n",
      "Common vocab count   : 4031 / 5852 (union)\n",
      "\n",
      "=== ROW COUNTS (WITH DUPLICATES) ===\n",
      "Total rows used from file1 (keyed rows): 5051\n",
      "Total rows used from file2 (keyed rows): 4832\n",
      "\n",
      "=== OUTPUT FILES (ROWS WRITTEN) ===\n",
      "common_merged.csv     : 4031 rows\n",
      "unique_file1.csv      : 1020 rows\n",
      "unique_file2.csv      : 801 rows\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Dict, Tuple, Iterable, Set, Any, Optional\n",
    "\n",
    "\n",
    "def _open_csv_autocodec(path: str, modes: Iterable[str] = (\"utf-8-sig\", \"utf-8\", \"latin-1\")):\n",
    "    \"\"\"\n",
    "    Try opening CSV with several common encodings. Yields an open file object.\n",
    "    \"\"\"\n",
    "    last_err = None\n",
    "    for enc in modes:\n",
    "        try:\n",
    "            return open(path, newline=\"\", encoding=enc), enc\n",
    "        except UnicodeError as e:\n",
    "            last_err = e\n",
    "    # if all failed, re-raise last error\n",
    "    raise last_err if last_err else OSError(f\"Cannot open {path}\")\n",
    "\n",
    "\n",
    "def _read_csv_rows(path: str) -> Tuple[List[List[str]], str]:\n",
    "    \"\"\"\n",
    "    Read all rows from CSV, returning (rows, encoding_used).\n",
    "    Preserves all columns, does not strip header (bo nie mamy gwarancji, że jest).\n",
    "    \"\"\"\n",
    "    f, enc = _open_csv_autocodec(path)\n",
    "    with f:\n",
    "        reader = csv.reader(f)\n",
    "        rows: List[List[str]] = []\n",
    "        for row in reader:\n",
    "            # Normalize to strings, strip whitespace around cells\n",
    "            if not row:\n",
    "                continue\n",
    "            cleaned = [cell.strip() for cell in row]\n",
    "            # Skip if all cells are empty after stripping\n",
    "            if not any(cleaned):\n",
    "                continue\n",
    "            rows.append(cleaned)\n",
    "    return rows, enc\n",
    "\n",
    "\n",
    "def _index_by_column(rows: List[List[str]], key_index: int) -> Dict[str, List[List[str]]]:\n",
    "    \"\"\"\n",
    "    Map: word -> list of full rows where 'word' is rows[i][key_index].\n",
    "    Skips rows that do not have the requested column.\n",
    "    \"\"\"\n",
    "    idx: Dict[str, List[List[str]]] = defaultdict(list)\n",
    "    for r in rows:\n",
    "        if len(r) <= key_index:\n",
    "            continue\n",
    "        key = r[key_index].strip()\n",
    "        if key == \"\":\n",
    "            continue\n",
    "        idx[key].append(r)\n",
    "    return dict(idx)\n",
    "\n",
    "\n",
    "def _max_len_of_rows(rows: Iterable[List[str]]) -> int:\n",
    "    return max((len(r) for r in rows), default=0)\n",
    "\n",
    "\n",
    "def _pad_row(row: List[str], target_len: int) -> List[str]:\n",
    "    if len(row) >= target_len:\n",
    "        return row\n",
    "    return row + [\"\"] * (target_len - len(row))\n",
    "\n",
    "\n",
    "def _write_common_merged(\n",
    "    common_words: Iterable[str],\n",
    "    idx1: Dict[str, List[List[str]]],\n",
    "    idx2: Dict[str, List[List[str]]],\n",
    "    out_path: str,\n",
    "    header: bool = True,\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Zapisuje wszystkie dopasowania 'word' jako iloczyn kartezjański:\n",
    "    [word] + row_from_file1 + row_from_file2\n",
    "\n",
    "    Zwraca liczbę zapisanych wierszy.\n",
    "    \"\"\"\n",
    "    # policz maksymalną liczbę kolumn per plik, by wyrównać długości\n",
    "    max_c1 = _max_len_of_rows(r for rows in idx1.values() for r in rows)\n",
    "    max_c2 = _max_len_of_rows(r for rows in idx2.values() for r in rows)\n",
    "\n",
    "    count = 0\n",
    "    with open(out_path, \"w\", newline=\"\", encoding=\"utf-8-sig\", errors=\"replace\") as f:\n",
    "        w = csv.writer(f)\n",
    "        if header:\n",
    "            w.writerow([\"Word\"] + [f\"file1_col{i+1}\" for i in range(max_c1)] + [f\"file2_col{i+1}\" for i in range(max_c2)])\n",
    "        for word in sorted(common_words):\n",
    "            rows1 = idx1.get(word, [])\n",
    "            rows2 = idx2.get(word, [])\n",
    "            for r1 in rows1:\n",
    "                r1p = _pad_row(r1, max_c1)\n",
    "                for r2 in rows2:\n",
    "                    r2p = _pad_row(r2, max_c2)\n",
    "                    w.writerow([word] + r1p + r2p)\n",
    "                    count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def _write_unique_rows(\n",
    "    unique_words: Iterable[str],\n",
    "    idx: Dict[str, List[List[str]]],\n",
    "    out_path: str,\n",
    "    file_label: str,\n",
    "    header: bool = True,\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Dla każdego 'word' wypisuje WSZYSTKIE wiersze z jednego źródła:\n",
    "    [word] + row_from_that_file\n",
    "\n",
    "    Zwraca liczbę zapisanych wierszy.\n",
    "    \"\"\"\n",
    "    max_c = _max_len_of_rows(r for w in unique_words for r in idx.get(w, []))\n",
    "    count = 0\n",
    "    with open(out_path, \"w\", newline=\"\", encoding=\"utf-8-sig\", errors=\"replace\") as f:\n",
    "        w = csv.writer(f)\n",
    "        if header:\n",
    "            w.writerow([\"Word\"] + [f\"{file_label}_col{i+1}\" for i in range(max_c)])\n",
    "        for word in sorted(unique_words):\n",
    "            for r in idx.get(word, []):\n",
    "                w.writerow([word] + _pad_row(r, max_c))\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def compare_csv_words(\n",
    "    file1: str,\n",
    "    file2: str,\n",
    "    *,\n",
    "    file1_key_col: int = 1,  # 2nd column (0-based index)\n",
    "    file2_key_col: int = 0,  # 1st column (0-based index)\n",
    "    common_out: str = \"common_merged.csv\",\n",
    "    unique1_out: str = \"unique_file1.csv\",\n",
    "    unique2_out: str = \"unique_file2.csv\",\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Główna funkcja:\n",
    "\n",
    "    - file1: słowo brane z kolumny o indeksie file1_key_col (domyślnie 1 → 2. kolumna)\n",
    "    - file2: słowo brane z kolumny o indeksie file2_key_col (domyślnie 0 → 1. kolumna)\n",
    "\n",
    "    Zwraca słownik ze statystykami i zapisuje trzy pliki CSV:\n",
    "      - common_merged.csv: dopasowania (iloczyn kartezjański wierszy) bok-w-bok\n",
    "      - unique_file1.csv, unique_file2.csv: wiersze unikalne dla każdego pliku\n",
    "\n",
    "    Statystyki obejmują zarówno unikalny słownik (SET), jak i realną liczbę wierszy (z duplikatami).\n",
    "    \"\"\"\n",
    "    # Wczytaj oba pliki\n",
    "    rows1, enc1 = _read_csv_rows(file1)\n",
    "    rows2, enc2 = _read_csv_rows(file2)\n",
    "\n",
    "    # Zindeksuj po odpowiednich kolumnach\n",
    "    idx1 = _index_by_column(rows1, file1_key_col)\n",
    "    idx2 = _index_by_column(rows2, file2_key_col)\n",
    "\n",
    "    # Unikalne słowa\n",
    "    keys1: Set[str] = set(idx1.keys())\n",
    "    keys2: Set[str] = set(idx2.keys())\n",
    "\n",
    "    common_words: Set[str] = keys1 & keys2\n",
    "    unique1_words: Set[str] = keys1 - keys2\n",
    "    unique2_words: Set[str] = keys2 - keys1\n",
    "\n",
    "    # Liczby wierszy (z duplikatami) dla przejrzystości\n",
    "    total_rows_file1 = sum(len(v) for v in idx1.values())\n",
    "    total_rows_file2 = sum(len(v) for v in idx2.values())\n",
    "\n",
    "    # Zapisz wyniki\n",
    "    written_common = _write_common_merged(common_words, idx1, idx2, common_out)\n",
    "    written_unique1 = _write_unique_rows(unique1_words, idx1, unique1_out, \"file1\")\n",
    "    written_unique2 = _write_unique_rows(unique2_words, idx2, unique2_out, \"file2\")\n",
    "\n",
    "    # Statystyki słownikowe (unikalne słowa)\n",
    "    stats = {\n",
    "        # Metadane wejścia\n",
    "        \"file1_path\": file1,\n",
    "        \"file2_path\": file2,\n",
    "        \"file1_encoding\": enc1,\n",
    "        \"file2_encoding\": enc2,\n",
    "\n",
    "        # Unikalne słowa\n",
    "        \"unique_vocab_file1\": len(keys1),\n",
    "        \"unique_vocab_file2\": len(keys2),\n",
    "        \"common_vocab_count\": len(common_words),\n",
    "        \"unique_to_file1_vocab_count\": len(unique1_words),\n",
    "        \"unique_to_file2_vocab_count\": len(unique2_words),\n",
    "        \"total_union_vocab\": len(keys1 | keys2),\n",
    "\n",
    "        # Wiersze (z duplikatami)\n",
    "        \"total_rows_file1\": total_rows_file1,\n",
    "        \"total_rows_file2\": total_rows_file2,\n",
    "\n",
    "        # Ile wierszy zapisano w plikach wynikowych\n",
    "        \"rows_written_common\": written_common,\n",
    "        \"rows_written_unique_file1\": written_unique1,\n",
    "        \"rows_written_unique_file2\": written_unique2,\n",
    "\n",
    "        # Słowa (zestawy) – przydatne do dalszej obróbki\n",
    "        \"common_words\": common_words,\n",
    "        \"unique_words_file1\": unique1_words,\n",
    "        \"unique_words_file2\": unique2_words,\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "\n",
    "def _print_summary(stats: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    Ładne podsumowanie do konsoli.\n",
    "    \"\"\"\n",
    "    print(\"=== INPUT ===\")\n",
    "    print(f\"file1: {stats['file1_path']} (encoding: {stats['file1_encoding']})\")\n",
    "    print(f\"file2: {stats['file2_path']} (encoding: {stats['file2_encoding']})\")\n",
    "\n",
    "    print(\"\\n=== UNIQUE VOCAB (SETS) ===\")\n",
    "    print(f\"Unique vocab in file1: {stats['unique_vocab_file1']}\")\n",
    "    print(f\"Unique vocab in file2: {stats['unique_vocab_file2']}\")\n",
    "    print(f\"Common vocab count   : {stats['common_vocab_count']} / {stats['total_union_vocab']} (union)\")\n",
    "\n",
    "    print(\"\\n=== ROW COUNTS (WITH DUPLICATES) ===\")\n",
    "    print(f\"Total rows used from file1 (keyed rows): {stats['total_rows_file1']}\")\n",
    "    print(f\"Total rows used from file2 (keyed rows): {stats['total_rows_file2']}\")\n",
    "\n",
    "    print(\"\\n=== OUTPUT FILES (ROWS WRITTEN) ===\")\n",
    "    print(f\"common_merged.csv     : {stats['rows_written_common']} rows\")\n",
    "    print(f\"unique_file1.csv      : {stats['rows_written_unique_file1']} rows\")\n",
    "    print(f\"unique_file2.csv      : {stats['rows_written_unique_file2']} rows\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # PRZYKŁAD UŻYCIA – zmień ścieżki na swoje\n",
    "    file1 = r\"NGSL_lists\\NGSL-GR_rank.csv\"           # słowo w 2. kolumnie (index 1)\n",
    "    file2 = \"4_NGSL_lists_combined.csv\"      # słowo w 1. kolumnie (index 0)\n",
    "\n",
    "    stats = compare_csv_words(\n",
    "        file1,\n",
    "        file2,\n",
    "        file1_key_col=1,   # jeśli w file1 słowo jest w innej kolumnie, zmień indeks\n",
    "        file2_key_col=0,   # jeśli w file2 słowo jest w innej kolumnie, zmień indeks\n",
    "        common_out=\"common_merged.csv\",\n",
    "        unique1_out=\"unique_file1.csv\",\n",
    "        unique2_out=\"unique_file2.csv\",\n",
    "    )\n",
    "    _print_summary(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411c47a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roberta_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
