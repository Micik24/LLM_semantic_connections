{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f29a13e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mask at position 1:\n",
      "  Word 'Ġgrandmother': logit=-4.19, prob=0.0000, rank=41109 / 50265\n",
      "  Top predictions:\n",
      "          </s> | logit=12.08 | prob=0.0854\n",
      "           The | logit=11.20 | prob=0.0353\n",
      "\n",
      "Mask at position 2:\n",
      "  Word 'Ġgrandmother': logit=-2.90, prob=0.0000, rank=38365 / 50265\n",
      "  Top predictions:\n",
      "             : | logit=6.90 | prob=0.0250\n",
      "          </s> | logit=6.83 | prob=0.0234\n",
      "\n",
      "Mask at position 3:\n",
      "  Word 'Ġgrandmother': logit=-3.27, prob=0.0000, rank=42499 / 50265\n",
      "  Top predictions:\n",
      "          </s> | logit=7.05 | prob=0.0316\n",
      "             : | logit=6.85 | prob=0.0258\n",
      "\n",
      "Mask at position 4:\n",
      "  Word 'Ġgrandmother': logit=-3.11, prob=0.0000, rank=41060 / 50265\n",
      "  Top predictions:\n",
      "          </s> | logit=7.45 | prob=0.0475\n",
      "             , | logit=7.09 | prob=0.0333\n",
      "\n",
      "Mask at position 5:\n",
      "  Word 'Ġgrandmother': logit=-3.04, prob=0.0000, rank=40347 / 50265\n",
      "  Top predictions:\n",
      "          </s> | logit=7.62 | prob=0.0566\n",
      "             , | logit=7.16 | prob=0.0357\n",
      "\n",
      "Mask at position 6:\n",
      "  Word 'Ġgrandmother': logit=-3.00, prob=0.0000, rank=39970 / 50265\n",
      "  Top predictions:\n",
      "          </s> | logit=7.54 | prob=0.0530\n",
      "             , | logit=7.13 | prob=0.0355\n",
      "\n",
      "Mask at position 7:\n",
      "  Word 'Ġgrandmother': logit=-3.03, prob=0.0000, rank=40255 / 50265\n",
      "  Top predictions:\n",
      "          </s> | logit=7.51 | prob=0.0517\n",
      "             , | logit=7.15 | prob=0.0358\n",
      "\n",
      "Mask at position 8:\n",
      "  Word 'Ġgrandmother': logit=-3.08, prob=0.0000, rank=40611 / 50265\n",
      "  Top predictions:\n",
      "          </s> | logit=7.44 | prob=0.0472\n",
      "             , | logit=7.23 | prob=0.0381\n",
      "\n",
      "Mask at position 9:\n",
      "  Word 'Ġgrandmother': logit=-3.13, prob=0.0000, rank=40741 / 50265\n",
      "  Top predictions:\n",
      "             , | logit=7.27 | prob=0.0383\n",
      "          </s> | logit=7.27 | prob=0.0382\n",
      "\n",
      "Mask at position 10:\n",
      "  Word 'Ġgrandmother': logit=-3.25, prob=0.0000, rank=41446 / 50265\n",
      "  Top predictions:\n",
      "             , | logit=7.41 | prob=0.0423\n",
      "          </s> | logit=6.99 | prob=0.0276\n",
      "\n",
      "Mask at position 11:\n",
      "  Word 'Ġgrandmother': logit=-2.96, prob=0.0000, rank=39004 / 50265\n",
      "  Top predictions:\n",
      "          </s> | logit=6.94 | prob=0.0285\n",
      "             , | logit=6.81 | prob=0.0250\n",
      "\n",
      "Mask at position 12:\n",
      "  Word 'Ġgrandmother': logit=-2.58, prob=0.0000, rank=34060 / 50265\n",
      "  Top predictions:\n",
      "             . | logit=8.93 | prob=0.1002\n",
      "             : | logit=7.94 | prob=0.0373\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch\n",
    "\n",
    "def analyze_masks(sentence, model, tokenizer, search_word=None, top_n=5):\n",
    "    \"\"\"\n",
    "    For each <mask> token in the sentence:\n",
    "    - Show rank/logit/prob of a searched word (if provided).\n",
    "    - Show top_n most probable candidates.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits  # [batch, seq_len, vocab_size]\n",
    "\n",
    "    mask_token_id = tokenizer.mask_token_id\n",
    "    mask_positions = (inputs[\"input_ids\"] == mask_token_id).nonzero(as_tuple=True)[1]\n",
    "\n",
    "    search_word_id = None\n",
    "    if search_word:\n",
    "        search_word_id = tokenizer.convert_tokens_to_ids(search_word)\n",
    "\n",
    "    results = {}\n",
    "    for pos in mask_positions:\n",
    "        mask_logits = logits[0, pos]\n",
    "        probs = torch.softmax(mask_logits, dim=-1)\n",
    "\n",
    "        # Top-N predictions\n",
    "        top_logits, top_ids = torch.topk(mask_logits, top_n)\n",
    "        tokens = tokenizer.convert_ids_to_tokens(top_ids.tolist())\n",
    "        top_probs = probs[top_ids].tolist()\n",
    "\n",
    "        entry = {\n",
    "            \"top_predictions\": [\n",
    "                {\"token\": t, \"logit\": l.item(), \"prob\": p}\n",
    "                for t, l, p in zip(tokens, top_logits, top_probs)\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        # If searching a specific word\n",
    "        if search_word_id is not None:\n",
    "            word_logit = mask_logits[search_word_id].item()\n",
    "            word_prob = probs[search_word_id].item()\n",
    "\n",
    "            sorted_ids = torch.argsort(mask_logits, descending=True)\n",
    "            rank = (sorted_ids == search_word_id).nonzero(as_tuple=True)[0].item() + 1  # 1-based\n",
    "\n",
    "            entry[\"searched_word\"] = {\n",
    "                \"word\": search_word,\n",
    "                \"logit\": word_logit,\n",
    "                \"prob\": word_prob,\n",
    "                \"rank\": rank,\n",
    "                \"vocab_size\": mask_logits.shape[0]\n",
    "            }\n",
    "\n",
    "        results[pos.item()] = entry\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    model_name = \"roberta-base\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "\n",
    "    sentence = \"<mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask>\"\n",
    "\n",
    "    preds = analyze_masks(sentence, model, tokenizer, search_word=\"Ġgrandmother\", top_n=2)\n",
    "\n",
    "    for pos, info in preds.items():\n",
    "        if pos < 20:\n",
    "            print(f\"\\nMask at position {pos}:\")\n",
    "            if \"searched_word\" in info:\n",
    "                sw = info[\"searched_word\"]\n",
    "                print(f\"  Word '{sw['word']}': logit={sw['logit']:.2f}, prob={sw['prob']:.4f}, rank={sw['rank']} / {sw['vocab_size']}\")\n",
    "            print(\"  Top predictions:\")\n",
    "            for c in info[\"top_predictions\"]:\n",
    "                print(f\"    {c['token']:>10s} | logit={c['logit']:.2f} | prob={c['prob']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c88b64f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ġspecifically']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word = \" specifically\"\n",
    "tokens = tokenizer.tokenize(word)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17989ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roberta_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
