{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f29a13e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mask at position 1:\n",
      "  Word 'Ġpain': logit=0.97, prob=0.00000067, rank=10733 / 50265\n",
      "  Top predictions:\n",
      "             L | logit=12.13 | prob=0.04729617\n",
      "\n",
      "Mask at position 2:\n",
      "  Word 'Ġpain': logit=2.75, prob=0.00008734, rank=1681 / 50265\n",
      "  Top predictions:\n",
      "           Ġof | logit=8.40 | prob=0.02499210\n",
      "\n",
      "Mask at position 3:\n",
      "  Word 'Ġpain': logit=1.37, prob=0.00000512, rank=4879 / 50265\n",
      "  Top predictions:\n",
      "          Ġand | logit=11.72 | prob=0.16075793\n",
      "\n",
      "Mask at position 6:\n",
      "  Word 'Ġpain': logit=2.53, prob=0.00001743, rank=1714 / 50265\n",
      "  Top predictions:\n",
      "             , | logit=12.17 | prob=0.26642850\n",
      "\n",
      "Mask at position 7:\n",
      "  Word 'Ġpain': logit=1.81, prob=0.00005232, rank=2432 / 50265\n",
      "  Top predictions:\n",
      "          </s> | logit=8.33 | prob=0.03569919\n",
      "\n",
      "Mask at position 8:\n",
      "  Word 'Ġpain': logit=1.93, prob=0.00004543, rank=2527 / 50265\n",
      "  Top predictions:\n",
      "             , | logit=8.53 | prob=0.03357203\n",
      "\n",
      "Mask at position 9:\n",
      "  Word 'Ġpain': logit=1.87, prob=0.00003874, rank=2705 / 50265\n",
      "  Top predictions:\n",
      "          Ġand | logit=8.83 | prob=0.04083638\n",
      "\n",
      "Mask at position 10:\n",
      "  Word 'Ġpain': logit=2.59, prob=0.00008814, rank=1543 / 50265\n",
      "  Top predictions:\n",
      "          </s> | logit=8.52 | prob=0.03309135\n",
      "\n",
      "Mask at position 11:\n",
      "  Word 'Ġpain': logit=3.50, prob=0.00010286, rank=839 / 50265\n",
      "  Top predictions:\n",
      "             . | logit=11.40 | prob=0.27566451\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch\n",
    "\n",
    "def analyze_masks(sentence, model, tokenizer, search_word=None, top_n=5):\n",
    "    \"\"\"\n",
    "    For each <mask> token in the sentence:\n",
    "    - Show rank/logit/prob of a searched word (if provided).\n",
    "    - Show top_n most probable candidates.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits  # [batch, seq_len, vocab_size]\n",
    "\n",
    "    mask_token_id = tokenizer.mask_token_id\n",
    "    mask_positions = (inputs[\"input_ids\"] == mask_token_id).nonzero(as_tuple=True)[1]\n",
    "\n",
    "    search_word_id = None\n",
    "    if search_word:\n",
    "        search_word_id = tokenizer.convert_tokens_to_ids(search_word)\n",
    "\n",
    "    results = {}\n",
    "    for pos in mask_positions:\n",
    "        mask_logits = logits[0, pos]\n",
    "        probs = torch.softmax(mask_logits, dim=-1)\n",
    "\n",
    "        # Top-N predictions\n",
    "        top_logits, top_ids = torch.topk(mask_logits, top_n)\n",
    "        tokens = tokenizer.convert_ids_to_tokens(top_ids.tolist())\n",
    "        top_probs = probs[top_ids].tolist()\n",
    "\n",
    "        entry = {\n",
    "            \"top_predictions\": [\n",
    "                {\"token\": t, \"logit\": l.item(), \"prob\": p}\n",
    "                for t, l, p in zip(tokens, top_logits, top_probs)\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        # If searching a specific word\n",
    "        if search_word_id is not None:\n",
    "            word_logit = mask_logits[search_word_id].item()\n",
    "            word_prob = probs[search_word_id].item()\n",
    "\n",
    "            sorted_ids = torch.argsort(mask_logits, descending=True)\n",
    "            rank = (sorted_ids == search_word_id).nonzero(as_tuple=True)[0].item() + 1  # 1-based\n",
    "\n",
    "            entry[\"searched_word\"] = {\n",
    "                \"word\": search_word,\n",
    "                \"logit\": word_logit,\n",
    "                \"prob\": word_prob,\n",
    "                \"rank\": rank,\n",
    "                \"vocab_size\": mask_logits.shape[0]\n",
    "            }\n",
    "\n",
    "        results[pos.item()] = entry\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    model_name = \"roberta-base\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "\n",
    "    sentence = \"<mask> <mask> <mask> abdominals <mask> <mask> <mask> <mask> <mask> <mask>\" \n",
    "\n",
    "    preds = analyze_masks(sentence, model, tokenizer, search_word=\"Ġpain\", top_n=1)\n",
    "\n",
    "    for pos, info in preds.items():\n",
    "        if pos < 20:\n",
    "            print(f\"\\nMask at position {pos}:\")\n",
    "            if \"searched_word\" in info:\n",
    "                sw = info[\"searched_word\"]\n",
    "                print(f\"  Word '{sw['word']}': logit={sw['logit']:.2f}, prob={sw['prob']:.8f}, rank={sw['rank']} / {sw['vocab_size']}\")\n",
    "            print(\"  Top predictions:\")\n",
    "            for c in info[\"top_predictions\"]:\n",
    "                print(f\"    {c['token']:>10s} | logit={c['logit']:.2f} | prob={c['prob']:.8f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c88b64f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ġdivers', 'ions']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word = \" diversions\"\n",
    "tokens = tokenizer.tokenize(word)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17989ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roberta_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
